{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 585 - HW 4 - EDUARDO GALEOTE - A20552496"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 1 – Reading the data in CoNLL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll_format(file_path):\n",
    "    sequences = []\n",
    "    tags = []\n",
    "\n",
    "    current_sequence = []\n",
    "    current_tags = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Check for a new sequence\n",
    "            if not line:\n",
    "                if current_sequence and current_tags:\n",
    "                    sequences.append(current_sequence)\n",
    "                    tags.append(current_tags)\n",
    "                    current_sequence = []\n",
    "                    current_tags = []\n",
    "            else:\n",
    "                # Split the line into token and tag\n",
    "                token, tag = line.split('\\t')\n",
    "                current_sequence.append(token)\n",
    "                current_tags.append(tag)\n",
    "        \n",
    "        # Append any sequence left at the end of the file\n",
    "        if current_sequence and current_tags:\n",
    "            sequences.append(current_sequence)\n",
    "            tags.append(current_tags)\n",
    "\n",
    "    return sequences, tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences in the training dataset: 5432\n",
      "Number of sequences in the testing dataset: 940\n",
      "\n",
      "Tokens and tags of the first sequence in the training dataset:\n",
      "Identification (O)\n",
      "of (O)\n",
      "APC2 (O)\n",
      ", (O)\n",
      "a (O)\n",
      "homologue (O)\n",
      "of (O)\n",
      "the (O)\n",
      "adenomatous (B-Disease)\n",
      "polyposis (I-Disease)\n",
      "coli (I-Disease)\n",
      "tumour (I-Disease)\n",
      "suppressor (O)\n",
      ". (O)\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the training and testing datasets\n",
    "train_file_path = 'train.tsv'\n",
    "test_file_path = 'test.tsv'\n",
    "\n",
    "train_token_sequences, train_tag_sequences = read_conll_format(train_file_path)\n",
    "test_token_sequences, test_tag_sequences = read_conll_format(test_file_path)\n",
    "\n",
    "# Display the number of sequences in the training and testing datasets\n",
    "print(f\"Number of sequences in the training dataset: {len(train_token_sequences)}\")\n",
    "print(f\"Number of sequences in the testing dataset: {len(test_token_sequences)}\")\n",
    "\n",
    "# Display the tokens and tags of the first sequence in the training dataset\n",
    "print(\"\\nTokens and tags of the first sequence in the training dataset:\")\n",
    "for token, tag in zip(train_token_sequences[0], train_tag_sequences[0]):\n",
    "    print(f\"{token} ({tag})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 2 – Data Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each tag in the training data:\n",
      "O: 124819\n",
      "B-Disease: 5145\n",
      "I-Disease: 6122\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten the list of tags to make it easier to count\n",
    "flat_tags = [tag for sublist in train_tag_sequences for tag in sublist]\n",
    "\n",
    "# Count each of the tags\n",
    "tag_counts = Counter(flat_tags)\n",
    "\n",
    "# Display the count of each tag\n",
    "print(\"Count of each tag in the training data:\")\n",
    "for tag, count in tag_counts.items():\n",
    "    print(f\"{tag}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common diseases that appear together:\n",
      "DM: 120\n",
      "DMD: 109\n",
      "APC: 91\n",
      "ALD: 86\n",
      "PWS: 75\n",
      "WAS: 63\n",
      "myotonic dystrophy: 57\n",
      "G6PD deficiency: 57\n",
      "HD: 55\n",
      "PKU: 52\n",
      "aniridia: 50\n",
      "Duchenne muscular dystrophy: 44\n",
      "breast cancer: 42\n",
      "VHL: 40\n",
      "FAP: 39\n",
      "cancer: 37\n",
      "tumor: 37\n",
      "A - T: 37\n",
      "Tay - Sachs disease: 35\n",
      "TSD: 35\n"
     ]
    }
   ],
   "source": [
    "def extract_disease_phrases(token_sequences, tag_sequences):\n",
    "    disease_phrases = []\n",
    "\n",
    "    for tokens, tags in zip(token_sequences, tag_sequences):\n",
    "        phrase = []\n",
    "        for token, tag in zip(tokens, tags):\n",
    "            if tag == 'B-Disease':\n",
    "                if phrase:  # if the previous phrase is complete, append it to the list\n",
    "                    disease_phrases.append(' '.join(phrase))\n",
    "                    phrase = []  # start a new phrase\n",
    "                phrase.append(token)\n",
    "            elif tag == 'I-Disease' and phrase:\n",
    "                phrase.append(token)\n",
    "            elif phrase:  # if the previous phrase is complete, append it to the list\n",
    "                disease_phrases.append(' '.join(phrase))\n",
    "                phrase = []  # start a new phrase\n",
    "        \n",
    "        # Append any phrase left at the end of the sequence\n",
    "        if phrase:\n",
    "            disease_phrases.append(' '.join(phrase))\n",
    "\n",
    "    return disease_phrases\n",
    "\n",
    "# Extract disease phrases from the training data\n",
    "disease_phrases = extract_disease_phrases(train_token_sequences, train_tag_sequences)\n",
    "\n",
    "# Count the most common disease phrases\n",
    "disease_phrase_counts = Counter(disease_phrases)\n",
    "\n",
    "# Display the most common disease phrases\n",
    "print(\"\\nCommon diseases that appear together:\")\n",
    "for phrase, count in disease_phrase_counts.most_common(20):\n",
    "    print(f\"{phrase}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 3 – Building Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for the first 3 tokens of the first sequence in train:\n",
      "Token 1 features: ['word=identification', 'suffix=ion', 'prev_word=BOS', 'next_word=of', 'is_numeric=NONNUM']\n",
      "Token 2 features: ['word=of', 'suffix=of', 'prev_word=identification', 'next_word=apc2', 'is_numeric=NONNUM']\n",
      "Token 3 features: ['word=apc2', 'suffix=pc2', 'prev_word=of', 'next_word=,', 'is_numeric=NONNUM']\n"
     ]
    }
   ],
   "source": [
    "def token_features(token_sequence, tag_sequence, position):\n",
    "    # Feature for the current word\n",
    "    current_word = token_sequence[position].lower()\n",
    "    \n",
    "    # Feature for the suffix of the current word\n",
    "    suffix = current_word[-3:]\n",
    "    \n",
    "    # Feature for the previous word (or BOS if at the beginning)\n",
    "    previous_word = \"BOS\" if position == 0 else token_sequence[position - 1].lower()\n",
    "    \n",
    "    # Feature for the next word (or EOS if at the end)\n",
    "    next_word = \"EOS\" if position == len(token_sequence) - 1 else token_sequence[position + 1].lower()\n",
    "\n",
    "    # Check if the token is a number\n",
    "    is_numeric = \"NUM\" if current_word.isdigit() else \"NONNUM\"\n",
    "\n",
    "    # Return the feature list\n",
    "    features = [\n",
    "        f\"word={current_word}\",\n",
    "        f\"suffix={suffix}\",\n",
    "        f\"prev_word={previous_word}\",\n",
    "        f\"next_word={next_word}\",\n",
    "        f\"is_numeric={is_numeric}\"\n",
    "    ]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Apply the function to the train token and tag sequences\n",
    "train_features = []\n",
    "for tokens, tags in zip(train_token_sequences, train_tag_sequences):\n",
    "    sequence_features = [token_features(tokens, tags, i) for i in range(len(tokens))]\n",
    "    train_features.append(sequence_features)\n",
    "\n",
    "# Apply the function to the test token and tag sequences\n",
    "test_features = []\n",
    "for tokens, tags in zip(test_token_sequences, test_tag_sequences):\n",
    "    sequence_features = [token_features(tokens, tags, i) for i in range(len(tokens))]\n",
    "    test_features.append(sequence_features)\n",
    "\n",
    "# Apply the modified function to the first 3 tokens of the first sequence in the train dataset\n",
    "first_sequence_features = [token_features(train_token_sequences[0], train_tag_sequences[0], i) for i in range(3)]\n",
    "\n",
    "# Display the features for the first 3 tokens of the first sequence in the train dataset\n",
    "print(\"Features for the first 3 tokens of the first sequence in train:\")\n",
    "for i, features in enumerate(first_sequence_features, 1):\n",
    "    print(f\"Token {i} features: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 4 – Training a CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   B-Disease       0.86      0.69      0.77       960\n",
      "   I-Disease       0.87      0.73      0.79      1087\n",
      "           O       0.98      0.99      0.99     22450\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     24497\n",
      "   macro avg       0.90      0.80      0.85     24497\n",
      "weighted avg       0.97      0.97      0.97     24497\n",
      " samples avg       0.97      0.97      0.97     24497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pycrfsuite\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "\n",
    "# Function to convert labels to binary\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "\n",
    "    tagset = list(set(lb.classes_))\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "\n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels=[class_indices[cls] for cls in tagset],\n",
    "        target_names=tagset,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "# Train the CRF model\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(train_features, train_tag_sequences):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # Coefficient for L1 regularization\n",
    "    'c2': 1e-3,  # Coefficient for L2 regularization\n",
    "    'max_iterations': 50,  # Maximum number of iterations\n",
    "    'feature.possible_transitions': True  # Include possible transitions\n",
    "})\n",
    "\n",
    "trainer.train('bio_crf.model')\n",
    "\n",
    "# Load the trained model\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('bio_crf.model')\n",
    "\n",
    "# Apply the model to the test dataset\n",
    "predicted_tag_sequences = [tagger.tag(xseq) for xseq in test_features]\n",
    "\n",
    "# Evaluate the model\n",
    "report = bio_classification_report(test_tag_sequences, predicted_tag_sequences)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 5 - Inspecting the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition weights:\n",
      "Transition from O to O: 2.342342\n",
      "Transition from O to B-Disease: 0.240565\n",
      "Transition from O to I-Disease: -7.488606\n",
      "Transition from B-Disease to O: -2.062396\n",
      "Transition from B-Disease to B-Disease: -5.738875\n",
      "Transition from B-Disease to I-Disease: 1.754811\n",
      "Transition from I-Disease to O: -1.264343\n",
      "Transition from I-Disease to B-Disease: -3.704388\n",
      "Transition from I-Disease to I-Disease: 2.72729\n",
      "\n",
      "State feature weights for 'is_numeric':\n",
      "Feature is_numeric=NONNUM, Label O: -0.008705\n",
      "Feature is_numeric=NONNUM, Label B-Disease: -0.195014\n",
      "Feature is_numeric=NONNUM, Label I-Disease: -1.257853\n",
      "Feature is_numeric=NUM, Label O: 2.791767\n",
      "Feature is_numeric=NUM, Label I-Disease: 0.789793\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('bio_crf.model')\n",
    "\n",
    "# Show parameter weights for transitions between the 3 tag types\n",
    "transitions = tagger.info().transitions\n",
    "print(\"Transition weights:\")\n",
    "for (label_from, label_to), weight in transitions.items():\n",
    "    if label_from in [\"B-Disease\", \"I-Disease\", \"O\"] and label_to in [\"B-Disease\", \"I-Disease\", \"O\"]:\n",
    "        print(f\"Transition from {label_from} to {label_to}: {weight}\")\n",
    "\n",
    "# Show parameter weights assigned to the \"is_numeric\" feature\n",
    "state_features = tagger.info().state_features\n",
    "print(\"\\nState feature weights for 'is_numeric':\")\n",
    "for (attribute, label), weight in state_features.items():\n",
    "    if \"is_numeric\" in attribute:\n",
    "        print(f\"Feature {attribute}, Label {label}: {weight}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM 6 – Document level performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-level Precision: 0.9682875264270613\n",
      "Document-level Recall: 0.849721706864564\n"
     ]
    }
   ],
   "source": [
    "def aggregate_to_document_level(tags):\n",
    "    \"\"\"\n",
    "    Aggregates token-level tags to a document-level label.\n",
    "    \n",
    "    Args:\n",
    "    tags (list of str): The sequence of tags for tokens in a document.\n",
    "    \n",
    "    Returns:\n",
    "    int: 1 if there's at least one \"B-Disease\" tag, 0 otherwise.\n",
    "    \"\"\"\n",
    "    return 1 if \"B-Disease\" in tags else 0\n",
    "\n",
    "# Apply the function to both true and predicted document-level labels from the test set\n",
    "true_doc_labels = [aggregate_to_document_level(seq) for seq in test_tag_sequences]\n",
    "predicted_doc_labels = [aggregate_to_document_level(seq) for seq in predicted_tag_sequences]\n",
    "\n",
    "# Compute document level precision and recall\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "doc_precision = precision_score(true_doc_labels, predicted_doc_labels)\n",
    "doc_recall = recall_score(true_doc_labels, predicted_doc_labels)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Document-level Precision: {doc_precision}\")\n",
    "print(f\"Document-level Recall: {doc_recall}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
